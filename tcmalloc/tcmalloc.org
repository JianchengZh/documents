#+AUTHOR:    Peng Zhang
#+EMAIL:     pengzhangdev@gmail.com

* tcmalloc2.1 浅析

** 简介
   tcmalloc(thread cached malloc) 是由google为并发程序而开发的内存分配管理器.tcmalloc致力于
   减少多线程内存请求时对锁的竞争, 在对小内存的申请时, 可以在无需锁的
   情况下高效获取内存;而在获取大内存时,使用高校的spinlocks.正因为
   tcmalloc是在线程局部空间(TLS)预先存储部分空闲内存用于分配, 在程序刚
   启动时,其所占用的内存会比dlmalloc或其他的内存管理器更大,但其增长速
   幅度比其他管理器小,所以,在后期,实际占用内存空间会相接近.

** 原理简析

*** overview

    [[file:tcmalloc.png]]

    tcmalloc为每一个线程分配一个线程本地缓存(Thread Cache, 以下简称TC)．所有小对象
    (<256K)都会优先从Thread Cache分配．而当Thread Cache没有足够空闲内
    存时，就会从Central Cache(以下简称CC)申请内存. 而当Thread Cache内存富裕时,会将
    内存返回给Central Cache. Central Cache 是以进程为单位存在,Thread
    Cache是以线程为单位存在.
    对于大内存(>256K), 直接从Page Heap (以下简称PH)按页对齐(4K)申请.
    通常情况下, 一连串的页面(4k)可以多个小内存序列,每个序列元素等大小.
    TC, CC, PH 的关系是, TC 向CC申请内存并GC给CC. CC 向PH 申请内存并GC
    给PH.
    在TC中的数据单位时字节, 按大小为单位分类,每个类中时链表.
    在PH中的数据单位时Page(4K), 按PageNum分类,每个分类内部用链表管理,
    第PageNum类的链表结点为PageNum个Page.
    在CC中存在最多的数据结构,它连接着TC和PH. 其存放了来自CC的slot结构,
    和来自PH的PH的span结构.
    数据的移动. 所有的数据从TC<->CC<->PH 都是批量(batch)移动.从TC申请
    或释放的内存都会优先从CC的slots数组处理. slots存放的就是最近从TC释
    放的内存,用于快速的TC内存申请.如果slots条件不满足,就会操作CC中的
    spans对象.所有移动的数据的大小和TC中的最大大小都是在动态调整的.

*** 小对象内存分配
    [[file:threadheap.gif]]

    上图为小内存管理时的sizemap分类的示意图.小内存的管理都处于
    ThreadCache中.所有对于256k以下的内存申请都是从TC中获取.
    个人把小内存分配,理解为3级内存请求.进程向TC请求内存, TC向CC请求内
    存,CC向PH请求内存.

**** 进程向TC请求和释放内存内存

***** TC内存管理
      首先, 在进程空间中,对于每一个线程,存在与其对应的TC, 所有的TC被用
      链表串联,不属于任何一个线程独有.通过这种,每一个TC都可以看到任何
      一个TC.
      如上图, 在TC中对内存进行了分类管理,每一个请求的内存大小都会向上
      取整到对应分类,然后直接从对应的链表中取出一项.


***** 进程向TC申请内存

      + 将请求内存向上对其到size class.
      + 从对应size class中查找空闲内存, 如果存在,直接返回.
      + 如果size class中无空闲内存,则触发向CC请求内存的机制.

***** 进程向TC释放内存

      + 从释放内存的地址,查找对应的pageID.
      + 如果page ID 属于TC, 并且TC的Heap存在,则释放到TC中
      + 如果PageID属于TC, 而TC的Heap不存在(跨线程内存申请和释放, 申请
        线程被销毁的情况下),则释放到CC中, 参考TC向CC释放内存
      + 如果pageID属于PH中(大内存), 则直接释放到PH中.


**** TC向CC请求和释放内存

***** CC的内存管理.
      在CC中同样维护了与TC中对应的分类箱子.每个类别中是一个
      CentralFreeList类. 该类中维护了一个slots双向链表, 用于快速分配内
      存给CC并接收释放的内存, 其内存粒度与TC中相同.同样,该类中也维护了两个span双向链表,
      empty(不包含空闲块)和nonempty(包含空闲块).span会在这两个链表中移
      动.
      Span是个什么东西呢?它是PH内存管理的一个粒度,其表示的内存大小为
      page(4K)的倍数.同时,它包含了更小的粒度单位objects. 所以,也可以认
      为它是CC和PH之间移动的内存单元.
      所以,Span和slots的关系是,spans可以拆分成slots

      这里,我们认为span属于PH的,所以,跟span的相关操作我们在PH讲解.


#+BEGIN_SRC cpp
class CentralFreeList {
   // ...

private:
   //...

  // We keep linked lists of empty and non-empty spans.
  size_t   size_class_;     // My size class
  Span     empty_;          // Dummy header for list of empty spans
  Span     nonempty_;       // Dummy header for list of non-empty spans
  size_t   num_spans_;      // Number of spans in empty_ plus nonempty_
  size_t   counter_;        // Number of free objects in cache entry

  // Here we reserve space for TCEntry cache slots.  Space is preallocated
  // for the largest possible number of entries than any one size class may
  // accumulate.  Not all size classes are allowed to accumulate
  // kMaxNumTransferEntries, so there is some wasted space for those size
  // classes.
  TCEntry tc_slots_[kMaxNumTransferEntries];

  // ...
};
#+END_SRC

#+BEGIN_SRC cpp
// Information kept for a span (a contiguous run of pages).
struct Span {
  PageID        start;          // Starting page number
  Length        length;         // Number of pages in span
  Span*         next;           // Used when in link list
  Span*         prev;           // Used when in link list
  void*         objects;        // Linked list of free objects
  unsigned int  refcount : 16;  // Number of non-free objects // 当refcount为0, 则释放给PageHeap.
  unsigned int  sizeclass : 8;  // Size-class for small objects (or 0)  // 这个是TC的 SizeClass 分类.因为每个分类对应一个CentralFreeList,每个List对应1个slots和2个spans. 所以,spans中的objects都统一属于某个SizeClass, 这里需要维护这个数据对object的.
  unsigned int  location : 2;   // Is the span on a freelist, and if so, which?  // 在empty/nonempty list?
  unsigned int  sample : 1;     // Sampled object?

#undef SPAN_HISTORY
#ifdef SPAN_HISTORY
  // For debugging, we can keep a log events per span
  int nexthistory;
  char history[64];
  int value[64];
#endif

  // What freelist the span is on: IN_USE if on none, or normal or returned
  enum { IN_USE, ON_NORMAL_FREELIST, ON_RETURNED_FREELIST };
};
#+END_SRC

***** TC向CC请求内存
      TC只有在其对应的分类中,不存在空闲块时,才会向CC的对应分类申请
      batch\_size的空闲块.
      + 根据当前请求的内存,找到对应的分类,和该分类下的默认向CC请求的对
        象个数(batch\_size). 在该分类free list的最大长度和batch\_size中
        取最小值为需要申请的对象个数(num\_to\_move).
      + 基于慢启动算法,缓慢增加当前分类的free list容量.
      + 从CC的对应分类中的slots对像,获取相应数量的objects.
      + 如果slots不满足,则从spans对象中获取相应的objects.
      + 如果spans不满足(nonempty 为NULL),则触发CC向PH请求内存.

#+BEGIN_SRC cpp
inline void* ThreadCache::Allocate(size_t size, size_t cl) {
  // size 已经被向上对齐, cl为分类的箱号
  ASSERT(size <= kMaxSize);
  // kMaxSzie == 256 * 1024
  ASSERT(size == Static::sizemap()->ByteSizeForClass(cl));
  // sizemap() 为分类的数组.每个成员为链表.
  // ByteSizeForClass是取出对应箱号内的理论内存大小.

  // 以上assert 检查,理应在调用该函数之前保证.

  FreeList* list = &list_[cl];
  if (list->empty()) {
    return FetchFromCentralCache(cl, size);
  }
  size_ -= size;
  return list->Pop();
}
#+END_SRC

      我们重点描述下,TC向CC申请内存的过程.首先,我们需要知道,CC也按照TC
      的内存分类方式,存在各个分类的箱子. 所以,实际上是向CC中的对应分类
      获取一连串的空闲内存.
      首先,我们得确定,移动的内存数量,也就是对应分类的内存块个数.默认情
      况下, 有一个规则确定每个分类对应的该移动的内存数量.以64K为基准,除
      以对应分类的内存大小,算出来的为移动的内存数量.但是,对于一些极小内
      存,这个值将很大,所以,我们限制最大为32768个,同理,对于极大内存,这个值
      <=1,会导致这个分类的内存请求每次都向CC请求,所以,我们这只最小为2,
      保证最多每2次向CC请求一次内存.下面为,默认的分类和对应的移动数量.
      #+BEGIN_EXAMPLE
      idx : class_size : num_to_move_objs : num_to_move_pages
      1 : 8 : 8192 : 2
      2 : 16 : 4096 : 2
      3 : 32 : 2048 : 2
      4 : 48 : 1365 : 2
      5 : 64 : 1024 : 2
      6 : 80 : 819 : 2
      7 : 96 : 682 : 2
      8 : 112 : 585 : 2
      9 : 128 : 512 : 2
      10 : 144 : 455 : 2
      11 : 160 : 409 : 2
      12 : 176 : 372 : 2
      13 : 192 : 341 : 2
      14 : 208 : 315 : 2
      15 : 224 : 292 : 2
      16 : 240 : 273 : 2
      17 : 256 : 256 : 2
      18 : 288 : 227 : 2
      19 : 320 : 204 : 2
      20 : 352 : 186 : 2
      21 : 384 : 170 : 2
      22 : 416 : 157 : 2
      23 : 448 : 146 : 2
      24 : 480 : 136 : 2
      25 : 512 : 128 : 2
      26 : 576 : 113 : 2
      27 : 640 : 102 : 2
      28 : 704 : 93 : 2
      29 : 768 : 85 : 2
      30 : 832 : 78 : 2
      31 : 896 : 73 : 2
      32 : 960 : 68 : 2
      33 : 1024 : 64 : 2
      34 : 1152 : 56 : 2
      35 : 1280 : 51 : 2
      36 : 1408 : 46 : 2
      37 : 1536 : 42 : 2
      38 : 1792 : 36 : 2
      39 : 2048 : 32 : 2
      40 : 2304 : 28 : 2
      41 : 2560 : 25 : 2
      42 : 2816 : 23 : 3
      43 : 3072 : 21 : 2
      44 : 3328 : 19 : 3
      45 : 4096 : 16 : 2
      46 : 4608 : 14 : 3
      47 : 5120 : 12 : 2
      48 : 6144 : 10 : 3
      49 : 6656 : 9 : 5
      50 : 8192 : 8 : 2
      51 : 9216 : 7 : 5
      52 : 10240 : 6 : 4
      53 : 12288 : 5 : 3
      54 : 13312 : 4 : 5
      55 : 16384 : 4 : 2
      56 : 20480 : 3 : 5
      57 : 24576 : 2 : 3
      58 : 26624 : 2 : 7
      59 : 32768 : 2 : 4
      60 : 40960 : 2 : 5
      61 : 49152 : 2 : 6
      62 : 57344 : 2 : 7
      63 : 65536 : 2 : 8
      64 : 73728 : 2 : 9
      65 : 81920 : 2 : 10
      66 : 90112 : 2 : 11
      67 : 98304 : 2 : 12
      68 : 106496 : 2 : 13
      69 : 114688 : 2 : 14
      70 : 122880 : 2 : 15
      71 : 131072 : 2 : 16
      72 : 139264 : 2 : 17
      73 : 147456 : 2 : 18
      74 : 155648 : 2 : 19
      75 : 163840 : 2 : 20
      76 : 172032 : 2 : 21
      77 : 180224 : 2 : 22
      78 : 188416 : 2 : 23
      79 : 196608 : 2 : 24
      80 : 204800 : 2 : 25
      81 : 212992 : 2 : 26
      82 : 221184 : 2 : 27
      83 : 229376 : 2 : 28
      84 : 237568 : 2 : 29
      85 : 245760 : 2 : 30
      86 : 253952 : 2 : 31
      87 : 262144 : 2 : 32
      #+END_EXAMPLE
      以上只是默认值,这个值是会随着内存申请次数的增加而调整, google给这
      个算法取名为慢启动(slow-start)算法. 我们来看下.首先, list有个最大值,
      我们能移动的大小为list最大长度和默认中的最小值. 为了保证,在大量申
      请时的效率, 在max length < 默认值时,我们慢慢增长max length, 防止
      浪费空间,又能有效地逐渐提高效率. 在max length > 默认值时, 要么时
      大量请求,要么是由于请求的内存很大,导致默认值小,所以,这个时候,可以
      每次增加默认值大小.但最大移动数依然时默认的移动数.

#+BEGIN_SRC clisp
// slow-start
        (setq batch_size num_to_move)
        (setq list_length get_list_length_max_length)
        (fetch-mem (min batch_size list_length))
        (set-list-max-length 
                (if (< list_length batch_size)
                       (+ list_length 1)
                      (+ list_length batch_size)))
#+END_SRC

#+BEGIN_SRC cpp
// Remove some objects of class "cl" from central cache and add to thread heap.
// On success, return the first object for immediate use; otherwise return NULL.
void* ThreadCache::FetchFromCentralCache(size_t cl, size_t byte_size) {
  FreeList* list = &list_[cl];
  ASSERT(list->empty());
  // batch_size 为默认的移动数量
  const int batch_size = Static::sizemap()->num_objects_to_move(cl);

  // 考虑到list的大小,我们取list最大长度和batch_size中的最小值.
  const int num_to_move = min<int>(list->max_length(), batch_size);
  void *start, *end;
  // 从CC获取内存, 只是简单的链表删除操作
  int fetch_count = Static::central_cache()[cl].RemoveRange(
      &start, &end, num_to_move);

  ASSERT((start == NULL) == (fetch_count == 0));
  if (--fetch_count >= 0) {
    // size_为获取到的内存大小
    size_ += byte_size * fetch_count;
    // 添加到单向链表中.链表插入操作.
    list->PushRange(fetch_count, SLL_Next(start), end);
  }

  // 如果list的最大长度 < 默认移动长度, 则list最大长度+1, 慢慢靠近默认移动长度.
  if (list->max_length() < batch_size) {
    list->set_max_length(list->max_length() + 1);
  } else {
    // 否则,我们直接增长batch_size 长度, 当然不允许无限增长.
    int new_length = min<int>(list->max_length() + batch_size,
                              kMaxDynamicFreeListLength);
    // 必须保证max_length 时batch_size的整数倍,这样才能做到在N次batch_size的移动正好释放完list, 而不需要分割.
    new_length -= new_length % batch_size;
    ASSERT(new_length % batch_size == 0);
    list->set_max_length(new_length);
  }
  return start;
}
#+END_SRC

      这里实际从CC获取空闲空间的函数是RemoveRange函数.首先尝试直接从
      slots中获取,如果slots不够,则再从spans获取.
#+BEGIN_SRC cpp
int CentralFreeList::RemoveRange(void **start, void **end, int N) {
  ASSERT(N > 0);
  lock_.Lock();
  if (N == Static::sizemap()->num_objects_to_move(size_class_) &&
      used_slots_ > 0) {
    int slot = --used_slots_;
    ASSERT(slot >= 0);
    TCEntry *entry = &tc_slots_[slot];
    *start = entry->head;
    *end = entry->tail;
    lock_.Unlock();
    return N;
  }

  int result = 0;
  void* head = NULL;
  void* tail = NULL;
  // TODO: Prefetch multiple TCEntries?
  tail = FetchFromSpansSafe();
  if (tail != NULL) {
    SLL_SetNext(tail, NULL);
    head = tail;
    result = 1;
    while (result < N) {
      void *t = FetchFromSpans();
      if (!t) break;
      SLL_Push(&head, t);
      result++;
    }
  }
  lock_.Unlock();
  *start = head;
  *end = tail;
  return result;
}
#+END_SRC

#+BEGIN_SRC cpp
int SizeMap::NumMoveSize(size_t size) {
  if (size == 0) return 0;

  int num = static_cast<int>(64.0 * 1024.0 / size);
  if (num < 2) num = 2;

  if (num > FLAGS_tcmalloc_transfer_num_objects)
    num = FLAGS_tcmalloc_transfer_num_objects;

  return num;
}
#+END_SRC

***** TC向CC释放内存
      TC向CC释放内存的条件是,在进程向TC释放内存时, TC对应的分类free
      list的length > max\_length 或者 TC的总size > max\_size, 分别触发
      ListTooLong和Scavenge内存回收.

      ListTooLong 回收内存规则:
      + 如果list length < batch\_size , 则清空链表. 这种情况下,只有非频
        繁内存请求,才会length < batch\_size, 所以, 在时间和空间上,考虑
        优先空间,释放内存.
      + 如果list length > batch\_size, 则释放batch\_size个object.并且减
        少list的max length, 尽可能利用慢启动, 减少空间浪费的问题.

      Scavenge回收内存规则:
      + 遍历TC中所有的free list, 将(lowwatermark > 0)的list 释放
        (lowwatermark / 2 )个objects.
      + 如果lowwatermark > 0的list length > batch\_size, 则更新
        max\_length 为 max\_length - batch\_size, 利用慢启动算法,减慢内存增长的速度.
      + 重置所有list的 lowwatermark为当前的length. (lowwatermark会在
        list的length减小时更新,始终保持为list最小的length).
      + 偷取其他TC的max\_length. 由于当前TC容量不够,所以,偷取其他TC的容
        量,保证无用线程不会浪费过多空间.

      TC容量偷取:
      + 如果存在无人认领的内存(无人认领内存: 线程结束后(TC的Heap被释放)的
        内存, 最大为 8u * 4 << 20), 则优先从其领取需要的内存,增大当前线程的容量.
      + 上述条件不满足,则遍历所有的TC, 如果某个TC的容量 >
        kMinThreadCacheSize (kMaxSize * 2 = 512K) , 则偷取其容量.

#+BEGIN_SRC cpp
void ThreadCache::ListTooLong(FreeList* list, size_t cl) {
  const int batch_size = Static::sizemap()->num_objects_to_move(cl);
  // 如果list长度小于 batch_size, 释放所有, 否则, 释放batch_size个块.
  ReleaseToCentralCache(list, cl, batch_size);

  if (list->max_length() < batch_size) {
    // Slow start the max_length so we don't overreserve.
    list->set_max_length(list->max_length() + 1);
  } else if (list->max_length() > batch_size) {
    // If we consistently go over max_length, shrink max_length.  If we don't
    // shrink it, some amount of memory will always stay in this freelist.
    list->set_length_overages(list->length_overages() + 1);
    if (list->length_overages() > kMaxOverages) {
      ASSERT(list->max_length() > batch_size);
      list->set_max_length(list->max_length() - batch_size);
      list->set_length_overages(0);
    }
  }
}
#+END_SRC

      ReleaseToCentralCache 中执行了,将链表返回给CC的动作,里面涉及到了
      slots结构,我们来看下.
#+BEGIN_SRC cpp
// Remove some objects of class "cl" from thread heap and add to central cache
void ThreadCache::ReleaseToCentralCache(FreeList* src, size_t cl, int N) {
  ASSERT(src == &list_[cl]);
  if (N > src->length()) N = src->length();
  size_t delta_bytes = N * Static::sizemap()->ByteSizeForClass(cl);

  // We return prepackaged chains of the correct size to the central cache.
  // TODO: Use the same format internally in the thread caches?
  int batch_size = Static::sizemap()->num_objects_to_move(cl);
  while (N > batch_size) {
    void *tail, *head;
    src->PopRange(batch_size, &head, &tail);
    Static::central_cache()[cl].InsertRange(head, tail, batch_size);
    N -= batch_size;
  }
  void *tail, *head;
  src->PopRange(N, &head, &tail);
  Static::central_cache()[cl].InsertRange(head, tail, N);
  size_ -= delta_bytes;
}
#+END_SRC

      这个函数实际上是从TC释放到CC时调用.
#+BEGIN_SRC cpp
void CentralFreeList::InsertRange(void *start, void *end, int N) {
  SpinLockHolder h(&lock_);
  if (N == Static::sizemap()->num_objects_to_move(size_class_) &&
    MakeCacheSpace()) {
    // slots 是存在CC 的链表中的结构.
    // 每个CC的链表节点是slots.
    // 每个slots中的数据正好是TC中移动数据的大小.
    int slot = used_slots_++;
    ASSERT(slot >=0);
    ASSERT(slot < max_cache_size_);
    TCEntry *entry = &tc_slots_[slot];
    entry->head = start;
    entry->tail = end;
    return;
  }
  ReleaseListToSpans(start);
}
#+END_SRC

#+BEGIN_SRC cpp
void ThreadCache::Scavenge() {
  // If the low-water mark for the free list is L, it means we would
  // not have had to allocate anything from the central cache even if
  // we had reduced the free list size by L.  We aim to get closer to
  // that situation by dropping L/2 nodes from the free list.  This
  // may not release much memory, but if so we will call scavenge again
  // pretty soon and the low-water marks will be high on that call.
  //int64 start = CycleClock::Now();
  for (int cl = 0; cl < kNumClasses; cl++) {
    FreeList* list = &list_[cl];
    const int lowmark = list->lowwatermark();
    // 首先清理 lowmark > 0 的.就算某些lowmark值不对, 在该轮结束后,会通过clear_lowwatermark()重置,下一次将会成功释放大量内存.
    if (lowmark > 0) {
      const int drop = (lowmark > 1) ? lowmark/2 : 1;
      ReleaseToCentralCache(list, cl, drop);

      // Shrink the max length if it isn't used.  Only shrink down to
      // batch_size -- if the thread was active enough to get the max_length
      // above batch_size, it will likely be that active again.  If
      // max_length shinks below batch_size, the thread will have to
      // go through the slow-start behavior again.  The slow-start is useful
      // mainly for threads that stay relatively idle for their entire
      // lifetime.
      // 由于该TC内存快满了,所以,我们减少batch_size, 减慢慢启动算法,保证空间不会浪费太多.
      const int batch_size = Static::sizemap()->num_objects_to_move(cl);
      if (list->max_length() > batch_size) {
        list->set_max_length(
            max<int>(list->max_length() - batch_size, batch_size)); // 减少后和batch_size中的最大值.
      }
    }
    list->clear_lowwatermark();  //清理低水平标志位.其实就是设置为当前长度...
  }
  // 无耻地偷取其他线程的容量.
  IncreaseCacheLimit();
}
#+END_SRC

      以上是内存释放的情况,还有个保证自己线程容量充裕的无耻做法是,偷取其他线
      程的容量.偷取临近10个TC的 1 << 16容量. 当然,如果其容量小于最小值,就
      放过了．也就是说,对于很少启动慢启动的线程,其线程容量将会由于被偷
      取而持续减少, 有效控制了这种线程内存的浪费. 通过这种机制,有效地保
      证进程间空间不会浪费太多. 需求大的线程可以获得更多的容量,而需求
      小的线程获取少的容量.
      如果存在无人认领的内存,咱们就偷了!!所谓无人认领的内存,是指线程被
      释放后, 其释放的内存.

#+BEGIN_SRC cpp
void ThreadCache::IncreaseCacheLimitLocked() {
  if (unclaimed_cache_space_ > 0) {
    // Possibly make unclaimed_cache_space_ negative.
    unclaimed_cache_space_ -= kStealAmount;
    max_size_ += kStealAmount;
    return;
  }
  // Don't hold pageheap_lock too long.  Try to steal from 10 other
  // threads before giving up.  The i < 10 condition also prevents an
  // infinite loop in case none of the existing thread heaps are
  // suitable places to steal from.
  for (int i = 0; i < 10;
       ++i, next_memory_steal_ = next_memory_steal_->next_) {
    // Reached the end of the linked list.  Start at the beginning.
    if (next_memory_steal_ == NULL) {
      ASSERT(thread_heaps_ != NULL);
      // next_memory_steal_ 在初始化时默认为TC的Heap的链表头.
      // 所以,这个循环会不停轮流偷取链表里的所有线程,包括自己.
      next_memory_steal_ = thread_heaps_;
    }
    if (next_memory_steal_ == this ||
        next_memory_steal_->max_size_ <= kMinThreadCacheSize) {
      continue;
    }
    next_memory_steal_->max_size_ -= kStealAmount;
    max_size_ += kStealAmount;

    next_memory_steal_ = next_memory_steal_->next_;
    return;
  }
}
#+END_SRC

**** CC向PH 申请和释放内存

***** PH的内存管理
      PH的管理,跟TC一样也是进行了分类,挺复杂的.首先, 所有的内存,映射到
      进程空间的内存,都会占据着PH中的某个list. PH的内存是直接从系统的
      sbrk或者mmap分配的.同样, 大内存也是从PH分配的,所以,它很复杂!

      PH的分类,是按page数量进行. free\_ 从 0 - kMaxPages, 每个数组成员
      包含数组下标个pages, 也就是free\_[1\] 包含1个page长度的Spans.每
      个数组成员包含2个双向环形链表normal和returned.而大于kMaxPages的
      归属到large\_ 中.

      normal: 存放空闲的span list.
      returned: 存放通过madvise的MADV\_FREE 方式释放的span.前提时系统支
      持MADV\_FREE 或 MADV\_DONTNEED 否则就不释放内存.

      所谓madvise的MADV\_FREE 释放内存, 是内核实现的一种lazy free方式.
      在process通过madvise MADV\_FREE 方式通知kernel, 某段pages中的数据
      不再使用了, 如果kernel需要,可以清楚.如果process先于kernel再次访
      问了该区域,process可以快速获取到该位置的原先数据. 如果kernel先于
      process需要该pages,则当process访问时,会获得被清空的pages.

      如果我们系统不支持MADV\_FREE, 则使用
      MADV\_DONTNEED. MADV\_DONTNEED与MADV\_FREE的区别在于,
      MADV\_DONTNEED的情况下,不管什么情况下再次访问这段pages, 获得的总
      是被清0的内存区域.

      [[http://www.gossamer-threads.com/lists/linux/kernel/762930][more info about MADV\_FREE and MADV\_DONTNEED]]

      对于span, span中objects的地址和 span的PageID之间, 在PH中存在相应的算法进
      行映射. PageMap 是一个基数树(radix tree), 能将某个地址映射到对应
      的span. 而PageMapCache是HashTable能将对应的PageId映射到其size class.

#+BEGIN_SRC cpp
  // We segregate spans of a given size into two circular linked
  // lists: one for normal spans, and one for spans whose memory
  // has been returned to the system.
  struct SpanList {
    Span        normal;    // 存放被映射到进程空间的spans..
    Span        returned;  // 存放已经被释放回系统的spans..(?)
  };

  // List of free spans of length >= kMaxPages
  SpanList large_; // 所有> 128 pages的spans, 都归属到该list

  // Array mapping from span length to a doubly linked list of free spans
  SpanList free_[kMaxPages]; // kMaxPages = 1 << (20 - kPageShift) (= 128); 也就是说有128个分类.
#+END_SRC

***** CC 向PH 内存申请
      CC向PH申请内存的条件是, 当前CentralFreeList中空闲span不够.
      所有向PH申请的内存都是Page的N倍,所以,参数是
      N. PageHeap::New(Length n).
      + 首先, 搜索所有 >= N (N <= kMaxPages)的free list, 查找最符合要
        求的span.如果找到,则直接从双向链表中删除. 如果span比要求的大,
        则切分(Carve),将剩下的新申请一个span,放入对应的size class中.这
        种算法查找最适合的,但会导致地址不连续.
      + 如果所有的free list中没有匹配的,则遍历large list.由于large
        list中是未排序的,所以,在搜索时,需要不停地记录最接近请求大小的
        span.所以该算法是O(n), 费时.
      + 如果以上查找都失败,则PH就向系统申请N pages 并存入对应的size
        class.然后从头开始.如果申请失败,则返回NULL.


      我们延续之前TC向CC请求内存时的情况, 在slots不够时,会向spans请求.如
      下代码:
#+BEGIN_SRC cpp
void* CentralFreeList::FetchFromSpansSafe() {
  // 第一次尝试,如果失败,则意味着spans空间不够,需要向PH申请内存.
  void *t = FetchFromSpans();
  if (!t) {
    // 向PH申请内存,并划分获取的spans,用于该分类的slots.
    Populate();
    // 再次尝试获取objects.
    t = FetchFromSpans();
  }
  return t;
}
#+END_SRC

#+BEGIN_SRC cpp
// Fetch memory from the system and add to the central cache freelist.
void CentralFreeList::Populate() {
  // Release central list lock while operating on pageheap
  lock_.Unlock();
  // 获取该类别对应的需要从PH获取的page数量.具体数值可以参考上面slots分类的数据.
  const size_t npages = Static::sizemap()->class_to_pages(size_class_);

  Span* span;
  {
    SpinLockHolder h(Static::pageheap_lock());
    // 从PH 获取npages
    span = Static::pageheap()->New(npages);
    // 将这个span与该类别在PH中对应起来.
    if (span) Static::pageheap()->RegisterSizeClass(span, size_class_);
  }
  if (span == NULL) {
    Log(kLog, __FILE__, __LINE__,
        "tcmalloc: allocation failed", npages << kPageShift);
    lock_.Lock();
    return;
  }
  ASSERT(span->length == npages);
  // Cache sizeclass info eagerly.  Locking is not necessary.
  // (Instead of being eager, we could just replace any stale info
  // about this span, but that seems to be no better in practice.)
  for (int i = 0; i < npages; i++) {
    // 将pages的信息和对应的size_class 注册到PH中的hash表中, 也就是PageMapCache
    Static::pageheap()->CacheSizeClass(span->start + i, size_class_);
  }

  // Split the block into pieces and add to the free-list
  // TODO: coloring of objects to avoid cache conflicts?
  // 分割该span中objects到当前的free-list中.
  void** tail = &span->objects;
  char* ptr = reinterpret_cast<char*>(span->start << kPageShift);
  char* limit = ptr + (npages << kPageShift);
  const size_t size = Static::sizemap()->ByteSizeForClass(size_class_);
  int num = 0;
  while (ptr + size <= limit) {
    *tail = ptr;
    tail = reinterpret_cast<void**>(ptr);
    ptr += size;
    num++;
  }
  ASSERT(ptr <= limit);
  *tail = NULL;
  span->refcount = 0; // No sub-object in use yet

  // Add span to list of non-empty spans
  lock_.Lock();
  // 将该span添加到noneempty列表中.
  tcmalloc::DLL_Prepend(&nonempty_, span);
  ++num_spans_;
  counter_ += num;
}
#+END_SRC

#+BEGIN_SRC cpp
void* CentralFreeList::FetchFromSpans() {
  // 检查nonempty list, 如果为空,意味着没有空闲的span.
  if (tcmalloc::DLL_IsEmpty(&nonempty_)) return NULL;
  Span* span = nonempty_.next;

  ASSERT(span->objects != NULL);
  // span的refcount 指向被使用次数. 每一次被分配内存,引用++, 释放时引用--. 
  // 在释放时,如果refcount为0, 就会释放给PH.
  span->refcount++;
  void* result = span->objects;
  // 加入到链表
  span->objects = *(reinterpret_cast<void**>(result));
  if (span->objects == NULL) {
    // Move to empty list
    tcmalloc::DLL_Remove(span);
    tcmalloc::DLL_Prepend(&empty_, span);
    Event(span, 'E', 0);
  }
  counter_--;
  return result;
}
#+END_SRC

下面,我们看下PH的内存分配, 也就是PageHeap::New(Length n)的逻辑.

#+BEGIN_SRC cpp
Span* PageHeap::New(Length n) {
  ASSERT(Check());
  ASSERT(n > 0);

  // 搜索span规则.
  Span* result = SearchFreeAndLargeLists(n);
  if (result != NULL)
    return result;

  // ...

  // 增长内存, 实际是执行系统调用
  // Grow the heap and try again.
  if (!GrowHeap(n)) {
    ASSERT(Check());
    return NULL;
  }
  return SearchFreeAndLargeLists(n);
}
#+END_SRC

#+BEGIN_SRC cpp
Span* PageHeap::SearchFreeAndLargeLists(Length n) {
  ASSERT(Check());
  ASSERT(n > 0);

  // Find first size >= n that has a non-empty list
  // 从n开始查找,寻找第一个非空的链表.
  for (Length s = n; s < kMaxPages; s++) {
    Span* ll = &free_[s].normal;
    // If we're lucky, ll is non-empty, meaning it has a suitable span.
    if (!DLL_IsEmpty(ll)) {
      ASSERT(ll->next->location == Span::ON_NORMAL_FREELIST);
      // 找到, 然后,我们尝试分割.
      return Carve(ll->next, n);
    }
    // Alternatively, maybe there's a usable returned span.
    // returned 是通过madvice释放的内存.
    ll = &free_[s].returned;
    if (!DLL_IsEmpty(ll)) {
      // We did not call EnsureLimit before, to avoid releasing the span
      // that will be taken immediately back.
      // Calling EnsureLimit here is not very expensive, as it fails only if
      // there is no more normal spans (and it fails efficiently)
      // or SystemRelease does not work (there is probably no returned spans).
      if (EnsureLimit(n)) {
        // ll may have became empty due to coalescing
        if (!DLL_IsEmpty(ll)) {
          ASSERT(ll->next->location == Span::ON_RETURNED_FREELIST);
          return Carve(ll->next, n);
        }
      }
    }
  }
  // No luck in free lists, our last chance is in a larger class.
  // 这是个不幸的消息,我们只能搜索最后一个large_ 链表.
  return AllocLarge(n);  // May be NULL
}
#+END_SRC

由于large\_ 中的对象没有排序,所以,需要遍历所有,不停地匹配. 这个操作费
时,但基本上逻辑进到这里的几率不高.这里会检查PH的容量,并执行可能需要的
内存释放.

#+BEGIN_SRC cpp
Span* PageHeap::AllocLarge(Length n) {
  // find the best span (closest to n in size).
  // The following loops implements address-ordered best-fit.
  Span *best = NULL;

  
  搜索normal list
  for (Span* span = large_.normal.next;
       span != &large_.normal;
       span = span->next) {
    if (span->length >= n) {
      if ((best == NULL)
          || (span->length < best->length)
          || ((span->length == best->length) && (span->start < best->start))) {
        best = span;
        ASSERT(best->location == Span::ON_NORMAL_FREELIST);
      }
    }
  }

  Span *bestNormal = best;

  // 搜索returned list.
  for (Span* span = large_.returned.next;
       span != &large_.returned;
       span = span->next) {
    if (span->length >= n) {
      if ((best == NULL)
          || (span->length < best->length)
          || ((span->length == best->length) && (span->start < best->start))) {
        best = span;
        ASSERT(best->location == Span::ON_RETURNED_FREELIST);
      }
    }
  }

  // best来自normal
  if (best == bestNormal) {
    return best == NULL ? NULL : Carve(best, n);
  }


  // best 来自returned, 我们如果取回best,需要判断PH是否达到容量上限.
  // 只是检查.
  // true 为未达到上限.参数false表示,达到上限,不释放内存.
  if (EnsureLimit(n, false)) {
    return Carve(best, n);
  }

  // 容量上限,释放内存.
  // 释放内存的逻辑与TC的类似,从每个list中释放一部分.
  // 最后调用TCMalloc_SystemRelease 进行madvise释放.
  // 系统必须支持madvise, 否则tcmalloc无法工作.
  if (EnsureLimit(n, true)) {
    // best could have been destroyed by coalescing.
    // bestNormal is not a best-fit, and it could be destroyed as well.
    // We retry, the limit is already ensured:
    return AllocLarge(n);
  }

  // If bestNormal existed, EnsureLimit would succeeded:
  ASSERT(bestNormal == NULL);
  // We are not allowed to take best from returned list.
  return NULL;
}
#+END_SRC

我们来看下分割的行为.跟dlmalloc分割内存一样的. 都是将剩下的重新插入到
对应的分区中.

#+BEGIN_SRC cpp
Span* PageHeap::Carve(Span* span, Length n) {
  ASSERT(n > 0);
  ASSERT(span->location != Span::IN_USE);
  const int old_location = span->location;
  // 从链表中移除.
  RemoveFromFreeList(span);
  span->location = Span::IN_USE;
  Event(span, 'A', n);

  const int extra = span->length - n;
  ASSERT(extra >= 0);
  if (extra > 0) {
    // 将剩余部分生成新的span
    Span* leftover = NewSpan(span->start + n, extra);
    leftover->location = old_location;
    Event(leftover, 'S', extra);
    RecordSpan(leftover);
    // 插入对应的list
    PrependToFreeList(leftover);
    span->length = n;
    // 将span的地址区域和span的守地址在radix tree中对应起来.
    pagemap_.set(span->start + n - 1, span);
  }
  ASSERT(Check());
  return span;
}
#+END_SRC

然后我们看下GrowHeap, 是如何从系统获取内存的

#+BEGIN_SRC cpp
bool PageHeap::GrowHeap(Length n) {
  ASSERT(kMaxPages >= kMinSystemAlloc);
  if (n > kMaxValidPages) return false;
  // 判断需要请求的page数量.
  Length ask = (n>kMinSystemAlloc) ? n : static_cast<Length>(kMinSystemAlloc);
  size_t actual_size;
  void* ptr = NULL;

  // 确定添加ask的数量后,没有达到容量要求
  if (EnsureLimit(ask)) {
      ptr = TCMalloc_SystemAlloc(ask << kPageShift, &actual_size, kPageSize);
  }
  if (ptr == NULL) {
    if (n < ask) {
      // Try growing just "n" pages
      ask = n;
      if (EnsureLimit(ask)) {
        ptr = TCMalloc_SystemAlloc(ask << kPageShift, &actual_size, kPageSize);
      }
    }
    if (ptr == NULL) return false;
  }
  ask = actual_size >> kPageShift;
  RecordGrowth(ask << kPageShift);

  // 记录系统已经分配的page数量.
  uint64_t old_system_bytes = stats_.system_bytes;
  stats_.system_bytes += (ask << kPageShift);
  const PageID p = reinterpret_cast<uintptr_t>(ptr) >> kPageShift;
  ASSERT(p > 0);

  // If we have already a lot of pages allocated, just pre allocate a bunch of
  // memory for the page map. This prevents fragmentation by pagemap metadata
  // when a program keeps allocating and freeing large blocks.
  if (old_system_bytes < kPageMapBigAllocationThreshold
      && stats_.system_bytes >= kPageMapBigAllocationThreshold) {
    pagemap_.PreallocateMoreMemory();
  }

  // Make sure pagemap_ has entries for all of the new pages.
  // Plus ensure one before and one after so coalescing code
  // does not need bounds-checking.
  // 与前一个合并,如果前一个是空闲的话.
  if (pagemap_.Ensure(p-1, ask+2)) {
    // Pretend the new area is allocated and then Delete() it to cause
    // any necessary coalescing to occur.
    Span* span = NewSpan(p, ask);
    RecordSpan(span);
    Delete(span);
    ASSERT(Check());
    return true;
  } else {
    // We could not allocate memory within "pagemap_"
    // TODO: Once we can return memory to the system, return the new span
    return false;
  }
}
#+END_SRC

然后,就是跟系统互动的TCMalloc_SystemAlloc.其中有两个allocator, mmap和
sbrk.
它会遍历所有的allocs, 直到能成功分配内存.在我们的系统上,先尝试sbrk,然
后才是mmap.

#+BEGIN_SRC cpp
void* DefaultSysAllocator::Alloc(size_t size, size_t *actual_size,
                                 size_t alignment) {
  for (int i = 0; i < kMaxAllocators; i++) {
    if (!failed_[i] && allocs_[i] != NULL) {
      void* result = allocs_[i]->Alloc(size, actual_size, alignment);
      if (result != NULL) {
        return result;
      }
      failed_[i] = true;
    }
  }
  // After both failed, reset "failed_" to false so that a single failed
  // allocation won't make the allocator never work again.
  for (int i = 0; i < kMaxAllocators; i++) {
    failed_[i] = false;
  }
  return NULL;
}
#+END_SRC

***** CC 向PH 释放内存
      CC向PH释放内存的条件是, slots满,并且span中objects全部回收
      (refcount为0).
      前文提到,CC和PH之间移动的单位时span, 所以, 释放时需要的参数就是
      span.PageHeap::Delete(Span* span). 该函数的作用就是将释放的内存
      与其前后空闲内存合并,插入size class.
      + 首先,从PageMap获取到相连的span, 如果它们都是空闲的,则进行合并.
      + 将合并后的新span或者不需要合并的span插入对应的free list中.
      + PageHeap检查是否需要释放内存到系统.这里释放的机制与TC释放的机
        制有点不同,不会针对某个分类大小进行释放,而是针对整个PH进行释放.

#+BEGIN_SRC cpp
void PageHeap::Delete(Span* span) {
  ASSERT(Check());
  ASSERT(span->location == Span::IN_USE);
  ASSERT(span->length > 0);
  ASSERT(GetDescriptor(span->start) == span);
  ASSERT(GetDescriptor(span->start + span->length - 1) == span);
  const Length n = span->length;
  span->sizeclass = 0;
  span->sample = 0;
  // 设置为在normal list
  span->location = Span::ON_NORMAL_FREELIST;
  Event(span, 'D', span->length);
  // 与前后合并
  MergeIntoFreeList(span);  // Coalesces if possible
  // 内存释放的逻辑.
  IncrementalScavenge(n);
  ASSERT(Check());
}
#+END_SRC

首先我们看下合并的逻辑. 跟dlmalloc其实没差. 即使根据span的获取到对应的
pageID,然后查找(pageID - 1) 的page和(pageID +１)的page,如果都为空闲,合
并.

#+BEGIN_SRC cpp
void PageHeap::MergeIntoFreeList(Span* span) {
  ASSERT(span->location != Span::IN_USE);

  const PageID p = span->start;
  const Length n = span->length;
  // GetDescriptor 就是通过pagemap, 将pageID映射成span的地址.
  Span* prev = GetDescriptor(p-1);
  // 这里的location, 不是跟地址相关的,而是表示这个span存在的list(normal or returned)
  // 这里是保证, normal中的span不会和returned中的span进行合并.
  if (prev != NULL && prev->location == span->location) {
    // Merge preceding span into this span
    ASSERT(prev->start + prev->length == p);
    const Length len = prev->length;
    // 将上一个span从队列移除
    RemoveFromFreeList(prev);
    // 删除span对象
    DeleteSpan(prev);
    // 合并首地址
    span->start -= len;
    // 合并长度
    span->length += len;
    // 将新span的pageID和span的地址在pagemap中进行映射
    pagemap_.set(span->start, span);
    Event(span, 'L', len);
  }
  // same as above
  Span* next = GetDescriptor(p+n);
  if (next != NULL && next->location == span->location) {
    // Merge next span into this span
    ASSERT(next->start == p+n);
    const Length len = next->length;
    RemoveFromFreeList(next);
    DeleteSpan(next);
    span->length += len;
    pagemap_.set(span->start + span->length - 1, span);
    Event(span, 'R', len);
  }

  // 重新将生成的span插入相应的list中.
  PrependToFreeList(span);
}
#+END_SRC

下面,我们看下增量释放函数IncrementalScavenge.它不是每次都进行内存释放.当
某此内存未释放的情况下,会等待一段时间. 所以,PH的容量是允许超过的.

#+BEGIN_SRC cpp
void PageHeap::IncrementalScavenge(Length n) {
  // Fast path; not yet time to release memory
  // scaveng_counter_ 是一个超时计数,单位为page数.
  scavenge_counter_ -= n;
  if (scavenge_counter_ >= 0) return;  // Not yet time to scavenge

  // 回收率, 如果过低,则不回收
  const double rate = FLAGS_tcmalloc_release_rate;
  if (rate <= 1e-6) {
    // Tiny release rate means that releasing is disabled.
    scavenge_counter_ = kDefaultReleaseDelay;
    return;
  }

  // 尝试释放一个页面, 实际上是以span为单位释放. 也就是说,
  // 页面数会对齐到一个span中,然后释放该span.
  Length released_pages = ReleaseAtLeastNPages(1);

  // 实际没归还,则等待默认长度.
  // 没归还的原因是, 系统不支持madvise或者内存释放失败.
  if (released_pages == 0) {
    // Nothing to scavenge, delay for a while.
    // kDefaultReleaseDelay = 1 << 18; 基本等于是不再释放内存.
    scavenge_counter_ = kDefaultReleaseDelay;
  } else {
    // Compute how long to wait until we return memory.
    // FLAGS_tcmalloc_release_rate==1 means wait for 1000 pages
    // after releasing one page.
    // 释放成功,则计算下一次等待时间.
    const double mult = 1000.0 / rate;
    double wait = mult * static_cast<double>(released_pages);
    if (wait > kMaxReleaseDelay) {
      // Avoid overflow and bound to reasonable range.
      wait = kMaxReleaseDelay;
    }
    scavenge_counter_ = static_cast<int64_t>(wait);
  }
}
#+END_SRC

我们看下ReleaseAtLeastNPages, 这东西释放的单位为span, 所以,传入的参数,
page数量,实际上是指最小需要释放长度,达到了或者没有可释放的span,则停止,
否则,持续释放.

#+BEGIN_SRC cpp
Length PageHeap::ReleaseAtLeastNPages(Length num_pages) {
  Length released_pages = 0;

  // Round robin through the lists of free spans, releasing the last
  // span in each list.  Stop after releasing at least num_pages
  // or when there is nothing more to release.
  while (released_pages < num_pages && stats_.free_bytes > 0) {
    for (int i = 0; i < kMaxPages+1 && released_pages < num_pages;
         i++, release_index_++) {
      if (release_index_ > kMaxPages) release_index_ = 0;
      SpanList* slist = (release_index_ == kMaxPages) ?
          &large_ : &free_[release_index_];
      if (!DLL_IsEmpty(&slist->normal)) {
        // 获取normal非空的list, 释放其最后一个span.
        Length released_len = ReleaseLastNormalSpan(slist);
        // Some systems do not support release
        if (released_len == 0) return released_pages;
        released_pages += released_len;
      }
    }
  }
  return released_pages;
}
#+END_SRC

在ReleaseLastNormalSpan中,就是取出list中最后一个span, 调用
TCMalloc\_SystemRelease,释放.而 TCMalloc\_SystemRelease中,实际调用的是
madvise实现.


*** 大对象内存分配
    在分析小内存时,在请求内存数 > kMaxSize(256k)时, 则执行大内存分配.大
    内存的分配某些规则与CC向PH申请内存一样.
    + 根据请求大小,对齐到PH的分类中最接近的大小, 获取到num\_pages.
    + 执行PageHeap::New(Length n), 与CC向PH申请内存一样.

    而内存释放, 我们在小内存时,已经提到. 并且,其行为跟CC向PH释放内存逻
    辑一样.
    + 根据被释放的内存, 获取其pageID.
    + 如果pageID属于span, 则调用PageHeap::Delete(Span* span).

*** 算法

** 代码review

** 总结
*** tcmalloc优势
   + 我们可以将tcmalloc中的模块与dlmalloc中作映射. CC 看成dlmalloc中小
     内存模块, PH看成dlmalloc中的大内存模块.则tcmalloc中多了一个无锁的
     TC模块.所以,在小内存上存在的一个优势是,可以在一定范围内无锁获取和
     释放内存.
   + 第一条优势的前提是,TC空间足够. 但就算空间不够的情况下, TC向CC请求
     内存, 最多也是每2次TC请求需要加解一次锁.而CC向PH请求内存,在小内存
     的情况下,永远不可能出现每一次CC请求触发一次PH请求.
*** tcmalloc劣势 
   + tcmalloc的劣势,很明显,由于存在3级内存请求,和大量内存的预分配,其初
     始化的速度比dlmalloc慢很多. 
   + 由于对于每个线程存在TC, 空间浪费相对dlmalloc会多一些.虽然存在各种
     算法和优化了tcmalloc中数据块的结构,但在线程数多和内存请求次数大的
     情况下,依然不可避免地在TC中浪费了内存.
   + 内存碎片率高. 属于个人理解.在tcmalloc中,只对相连的pages(spans)进
     行合并,而pages的单位为4K, 相当于,这个page中只要存在被使用的内存,
     就永远不会与前后的page进行合并. 而在dlmalloc中,存在边界标记法,任
     何一个释放的内存块(任意大小),只要其相连块有空闲,则进行合并.


** 对mem测试的数据总结
   + 对图表的几个说明:
     + 图表是在线程数为4的基础上做的测试. 并且是在连续分配一定次数的内
       存后再连续释放,数据只能从一定程度上反映了tcmalloc与dlmalloc的性
       能差异.
     + 本次测试是计算出4个线程的内存请求和释放的平均时间, 和标准偏差.由
       于图表维度不够,只使用了平均时间作为实际的性能比较.
     + 测试时的两个变量分别为, 单次申请内存大小,和申请次数,性能指标为
       执行所有内存申请释放的线程平均时间.
     + 该数据不包含内存分配器初始化的时间(即,第一次内存分配时间).实际
       上,内存分配器初始化,tcmalloc花费的时间是dlmalloc多.但只
       是针对第一次,所以,不记录到图标数据中.
     + 以下所有提到的内存申请数,如未说明,都是指单次内存申请的大小.

   + 分析:
     + tcmalloc 内存分配概要:
       + tcmalloc 中存在分级请求内存的机制. 分为3级,分别为
         TC(ThreadCache), CC(Central Cache) 和 PH(PageHeap)
       + TC 向CC 申请内存, CC 向PH申请内存. 而他们之间的内存是批量移动,一
         般为申请内存对齐后的N倍进行移动.
       + TC 存在线程局部空间中. 向TC 申请内存不需要加解锁,向CC和PH 申
         请内存需要加解锁.
     + dlmalloc 内存分配概要:
       + dlmalloc每次内存申请都会执行加解锁操作.
       + 256byte以下的内存,从小内存分配. 256byte以上的从大内存分配.在
         空闲内存不够并且申请内存大于256K的,直接由mmap分配.

     + 首先,从图表可以得出一个结论,在单次内存30K以内的内存分配和释放,
       效率上,tcmalloc比dlmalloc高,并且在1K以内,申请次数大于26次的情况
       下,甚至可以达到10倍性能.原因是,在tcmalloc中,所有小于256k的内存
       都会优先从TC(避免加解锁操作)分配, 在TC不够的情况下,向CC申请 2 -
       32 倍的内存数量,并存放到TC中,相当于, N(N>2)次内存请求才执行1次
       加解锁. 而dlmalloc每次内存请求都会加解锁.所以,tcmalloc在小内存
       分配上,性能高于dlmalloc.
     + 而在30K - 256K, 在某些区域内,tcmalloc的性能反而不如dlmalloc. 可
       能原因如下: tcmalloc在每次往CC中拷贝数据时, 有个大小上限为64K,
       也有一个最小下限为2倍请求内存对齐后的大小. 所以,在这个
       区间内,相当于每2次内存请求都会加解一次锁. 而CC也有
       存在内存不足的情况,也会出现加解锁,进一步向PH申请空间. 所以,就相
       当于每次内存申请都会加解锁.至于,在申请次数达到一定值之
       后,tcmalloc的性能又高于dlmalloc的原因是:CC与PH之间的内存移动的
       值是动态修正的,也就是说,在申请次数达到一定值之后,CC向PH申请的内
       存数变大,而请求次数减少,导致tcmalloc的性能再次提升.
     + > 256K 的情况下,tcmalloc的性能也略好于dlmalloc. 原因未知.分析如
       下. 在这种情况下,对于dlmalloc而言,如果没有足够
       空闲内存(本次测试中不可能有足够空闲内存), dlmalloc会直接调用
       mmap进行内存分配, 相当与一次加解锁,一次系统调用的时间.而
       tcmalloc依然向PH申请内存,当然PH也会直接从系统分配.

   + 结论: (以下结论,只有1从图表中得出)
     + 大量小内存请求的情况下,tcmalloc性能高于dlmalloc, 节省了加解锁的
       时间.
     + 如果只存在少量的内存请求,即使是小内存,从总的申请内存时间
       上,dlmalloc会优于tcmalloc,原因是,在第一次内存申请时,tcmalloc初
       始化的时间是dlmalloc的近10倍.
     + 从代码中分析,tcmalloc的内存利用率小于dlmalloc,虽然,tcmalloc使用
       了各种算法来提高内存利用率,但依然无法避免线程局部空间中的内存浪
       费.

   + 该测试的局限性:
     + 由于该测试是连续内存申请之后,连续释放,所以无法测试申请已释放内
       存的效率.但从代码上和tcmalloc/dlmalloc加解锁的机制上看,tcmalloc
       依然会优于dlmalloc.
     + 无法测试对于生命周期超长的进程,内存的碎片率.


** 草稿

+ 主要函数
#+BEGIN_SRC cpp
extern "C" PERFTOOLS_DLL_DECL void* tc_malloc(size_t size) __THROW
extern "C" PERFTOOLS_DLL_DECL void tc_free(void* ptr) __THROW
extern "C" PERFTOOLS_DLL_DECL void* tc_calloc(size_t n,
                                              size_t elem_size) __THROW
extern "C" PERFTOOLS_DLL_DECL void tc_cfree(void* ptr) __THROW
extern "C" PERFTOOLS_DLL_DECL void* tc_realloc(void* old_ptr,
                                               size_t new_size) __THROW
extern "C" PERFTOOLS_DLL_DECL void* tc_new(size_t size)
extern "C" PERFTOOLS_DLL_DECL void tc_delete(void* p) __THROW
#+END_SRC

   真正分配内存的函数是do\_malloc函数.

*** 初始化

#+BEGIN_SRC cpp
// line: 1577 file: /root/git/gperftools/src/tcmalloc.cc
extern "C" PERFTOOLS_DLL_DECL void* tc_malloc(size_t size) __THROW {
  void* result = do_malloc_or_cpp_alloc(size);
  MallocHook::InvokeNewHook(result, size);
  return result;
}
// line: 1581
#+END_SRC

#+BEGIN_SRC cpp
// line: 1038 file: /root/git/gperftools/src/tcmalloc.cc
inline void* do_malloc_or_cpp_alloc(size_t size) {
  // tc_new_mode 是指是否使用cpp的new来替换malloc实现.
  // 默认情况下为使用malloc, 所以代码进入do_malloc(size);
  return tc_new_mode ? cpp_alloc(size, true) : do_malloc(size);
}
// line: 1041
#+END_SRC

#+BEGIN_SRC cpp
// line: 1118 file: /root/git/gperftools/src/tcmalloc.cc
inline void* do_malloc(size_t size) {
  void* ret = do_malloc_no_errno(size);
  // UNLIKELY 是gcc的优化扩展,表示其测试成立条件极低.
  //
  if (UNLIKELY(ret == NULL)) errno = ENOMEM;
  return ret;
}
// line: 1123
#+END_SRC
    [[UNLIKELY][UNLIKELY]]

#+BEGIN_SRC cpp
// line: 1107 file: /root/git/gperftools/src/tcmalloc.cc
inline void* do_malloc_no_errno(size_t size) {
  if (ThreadCache::have_tls &&
      LIKELY(size < ThreadCache::MinSizeForSlowPath())) {
    // 这里的逻辑实际上与 size <= kMaxSize类似.
    // 区别是,下面的逻辑会进行ThreadCache的初始化.
    // 而这里是直接获取ThreadCache中的Heap.
    return do_malloc_small(ThreadCache::GetCacheWhichMustBePresent(), size);
   // kMaxSize = 256 * 1024
  } else if (size <= kMaxSize) {
    // ThreadCache::GetCache 中会进行TC的初始化.
    return do_malloc_small(ThreadCache::GetCache(), size);
  } else {
    return do_malloc_pages(ThreadCache::GetCache(), size);
  }
}
// line: 1117
#+END_SRC
    [[MinSizeForSlowPath]]
    [[tcmalloc_tc_init]]

    #<<MinSizeForSlowPath>>
#+BEGIN_SRC cpp
// line:  436 file: /root/git/gperftools/src/thread_cache.h
inline size_t ThreadCache::MinSizeForSlowPath() {
#ifdef HAVE_TLS
  // 这里min_size_for_slow_path = kMaxSize + 1;
  // 具体设置这个值,在后面初始化时会提到.
  return threadlocal_data_.min_size_for_slow_path;
#else
  return 0;
#endif
}
// line:  443
#+END_SRC

    #<<UNLIKELY>>
#+BEGIN_SRC cpp
// line:   49 file: /root/git/gperftools/src/common.h
#define UNLIKELY(x) __builtin_expect(!!(x), 0)
// line:   49
#+END_SRC

    #<<tcmalloc_tc_init>>
#+BEGIN_SRC cpp
// line:  417 file: /root/git/gperftools/src/thread_cache.h
inline ThreadCache* ThreadCache::GetCache() {
  ThreadCache* ptr = NULL;
  if (!tsd_inited_) {
    // init Module, global data
    InitModule();
  } else {
    ptr = GetThreadHeap();
  }
  //  init ThreadCache
  if (ptr == NULL) ptr = CreateCacheIfNecessary();
  return ptr;
}
// line:  427
#+END_SRC
    [[InitModule]]
    [[CreateCacheIfNecessary]]

    #<<InitModule>>
#+BEGIN_SRC cpp
// line:  314 file: /root/git/gperftools/src/thread_cache.cc
void ThreadCache::InitModule() {
  SpinLockHolder h(Static::pageheap_lock());
  if (!phinited) {
    // 从环境变量 TCMALLOC_MAX_TOTAL_THREAD_CACHE_BYTES 获取ThreadCache的最大值
    const char *tcb = TCMallocGetenvSafe("TCMALLOC_MAX_TOTAL_THREAD_CACHE_BYTES");
    if (tcb) {
      set_overall_thread_cache_size(strtoll(tcb, NULL, 10));
    }
    // 进程空间变量和alloctor初始化.
    Static::InitStaticVars();
    threadcache_allocator.Init();
    phinited = 1;
  }
}
// line:  325
#+END_SRC
    [[InitStaticVars]]
    [[allocator\_init]]

    #<<InitStaticVars>>
#+BEGIN_SRC cpp
// line:   81 file: /root/git/gperftools/src/static_vars.cc
void Static::InitStaticVars() {
  // sizemap 初始化
  // 类似dlmalloc的分箱机制.
  // 按固定大小进行分类,在每个分类中存放对应大小的双向链表.
  sizemap_.Init();
  // 初始化span分配器
  span_allocator_.Init();
  span_allocator_.New(); // Reduce cache conflicts
  span_allocator_.New(); // Reduce cache conflicts
  stacktrace_allocator_.Init();
  bucket_allocator_.Init();
  // Do a bit of sanitizing: make sure central_cache is aligned properly
  CHECK_CONDITION((sizeof(central_cache_[0]) % 64) == 0);
  // 初始化central_cache_ 分类列表.
  for (int i = 0; i < kNumClasses; ++i) {
    central_cache_[i].Init(i);
  }

  // It's important to have PageHeap allocated, not in static storage,
  // so that HeapLeakChecker does not consider all the byte patterns stored
  // in is caches as pointers that are sources of heap object liveness,
  // which leads to it missing some memory leaks.
  // 初始化 PageHeap
  pageheap_ = new (MetaDataAlloc(sizeof(PageHeap))) PageHeap;
  // double linked list init
  DLL_Init(&sampled_objects_);
  Sampler::InitStatics();
}
// line:  102
#+END_SRC
    [[sizemap\_init]]

    #<<sizemap\_init>>
#+BEGIN_SRC cpp
// line:  122 file: /root/git/gperftools/src/common.cc
void SizeMap::Init() {
  // 初始化TC中对应TransferNumObjects.
  // TransferNumObjects 是
  InitTCMallocTransferNumObjects();

  // Do some sanity checking on add_amount[]/shift_amount[]/class_array[]
  // class 分类边界检查.
  // size 0 应该对应分类0
  // size Max 应该对应分类Max
  if (ClassIndex(0) != 0) {
    Log(kCrash, __FILE__, __LINE__,
        "Invalid class index for size 0", ClassIndex(0));
  }
  if (ClassIndex(kMaxSize) >= sizeof(class_array_)) {
    Log(kCrash, __FILE__, __LINE__,
        "Invalid class index for kMaxSize", ClassIndex(kMaxSize));
  }

  // Compute the size classes we want to use
  // 计算size classe 分类大小, 和对应的每个分类对应的
  // 计算结果如下:
  // class 1 :
  int sc = 1;   // Next size class to assign
  int alignment = kAlignment;
  CHECK_CONDITION(kAlignment <= kMinAlign);
  for (size_t size = kAlignment; size <= kMaxSize; size += alignment) {
    alignment = AlignmentForSize(size);
    CHECK_CONDITION((size % alignment) == 0);

    int blocks_to_move = NumMoveSize(size) / 4;
    size_t psize = 0;
    do {
      psize += kPageSize;
      // Allocate enough pages so leftover is less than 1/8 of total.
      // This bounds wasted space to at most 12.5%.
      while ((psize % size) > (psize >> 3)) {
        psize += kPageSize;
      }
      // Continue to add pages until there are at least as many objects in
      // the span as are needed when moving objects from the central
      // freelists and spans to the thread caches.
    } while ((psize / size) < (blocks_to_move));
    const size_t my_pages = psize >> kPageShift;

    if (sc > 1 && my_pages == class_to_pages_[sc-1]) {
      // See if we can merge this into the previous class without
      // increasing the fragmentation of the previous class.
      const size_t my_objects = (my_pages << kPageShift) / size;
      const size_t prev_objects = (class_to_pages_[sc-1] << kPageShift)
                                  / class_to_size_[sc-1];
      if (my_objects == prev_objects) {
        // Adjust last class to include this size
        class_to_size_[sc-1] = size;
        continue;
      }
    }

    // Add new class
    class_to_pages_[sc] = my_pages;
    class_to_size_[sc] = size;
    sc++;
  }
  if (sc != kNumClasses) {
    Log(kCrash, __FILE__, __LINE__,
        "wrong number of size classes: (found vs. expected )", sc, kNumClasses);
  }

  // Initialize the mapping arrays
  int next_size = 0;
  for (int c = 1; c < kNumClasses; c++) {
    const int max_size_in_class = class_to_size_[c];
    for (int s = next_size; s <= max_size_in_class; s += kAlignment) {
      class_array_[ClassIndex(s)] = c;
    }
    next_size = max_size_in_class + kAlignment;
  }

  // Double-check sizes just to be safe
  for (size_t size = 0; size <= kMaxSize;) {
    const int sc = SizeClass(size);
    if (sc <= 0 || sc >= kNumClasses) {
      Log(kCrash, __FILE__, __LINE__,
          "Bad size class (class, size)", sc, size);
    }
    if (sc > 1 && size <= class_to_size_[sc-1]) {
      Log(kCrash, __FILE__, __LINE__,
          "Allocating unnecessarily large class (class, size)", sc, size);
    }
    const size_t s = class_to_size_[sc];
    if (size > s || s == 0) {
      Log(kCrash, __FILE__, __LINE__,
          "Bad (class, size, requested)", sc, s, size);
    }
    if (size <= kMaxSmallSize) {
      size += 8;
    } else {
      size += 128;
    }
  }

  // Initialize the num_objects_to_move array.
  for (size_t cl = 1; cl  < kNumClasses; ++cl) {
    num_objects_to_move_[cl] = NumMoveSize(ByteSizeForClass(cl));
  }
}
// line:  218
#+END_SRC
    [[AlignmentForSize]]

    #<<AlignmentForSize>>
#+BEGIN_SRC cpp
// kPageShift = 13
// kNumClasses = 88
// kMinAlign = 16
// kAlignment  = 8
// kMaxSize    = 256 * 1024
// kPageSize   = 1 << kPageShift

// 计算结果如下:
// size         alignment
// >kMaxSize    kPageSize;
// >=128
// >= 16        16
// >= 8         8
int AlignmentForSize(size_t size) {
  int alignment = kAlignment;
  if (size > kMaxSize) {
    // Cap alignment at kPageSize for large sizes.
    alignment = kPageSize;
  } else if (size >= 128) {
    // Space wasted due to alignment is at most 1/8, i.e., 12.5%.
    alignment = (1 << LgFloor(size)) / 8;
  } else if (size >= kMinAlign) {
    // We need an alignment of at least 16 bytes to satisfy
    // requirements for some SSE types.
    alignment = kMinAlign;
  }
  // Maximum alignment allowed is page size alignment.
  if (alignment > kPageSize) {
    alignment = kPageSize;
  }
  CHECK_CONDITION(size < kMinAlign || alignment >= kMinAlign);
  CHECK_CONDITION((alignment & (alignment - 1)) == 0);
  return alignment;
}
#+END_SRC

    #<<allocator_init>>

    #<<CreateCacheIfNecessary>>
#+BEGIN_SRC cpp
// line:  345 file: /root/git/gperftools/src/thread_cache.cc
ThreadCache* ThreadCache::CreateCacheIfNecessary() {
  // Initialize per-thread data if necessary
  ThreadCache* heap = NULL;
  {
    SpinLockHolder h(Static::pageheap_lock());
    // 在某些老旧的glibc或者类unix系统中,如果在tcmalloc中过早调用pthread_self(),
    // 则会有可能引起崩溃.
#ifdef PTHREADS_CRASHES_IF_RUN_TOO_EARLY
    pthread_t me;
    if (!tsd_inited_) {
      memset(&me, 0, sizeof(me));
    } else {
      me = pthread_self();
    }
#else
    const pthread_t me = pthread_self();
#endif

    // 可能在之前, ThreadCache链表.
    // 初始化了. 我们先尝试搜索匹配该tid的ThreadCache结构.
    for (ThreadCache* h = thread_heaps_; h != NULL; h = h->next_) {
      if (h->tid_ == me) {
        heap = h;
        break;
      }
    }

    if (heap == NULL) heap = NewHeap(me);
  }

  // We call pthread_setspecific() outside the lock because it may
  // call malloc() recursively.  We check for the recursive call using
  // the "in_setspecific_" flag so that we can avoid calling
  // pthread_setspecific() if we are already inside pthread_setspecific().
  if (!heap->in_setspecific_ && tsd_inited_) {
    heap->in_setspecific_ = true;
    perftools_pthread_setspecific(heap_key_, heap);
#ifdef HAVE_TLS
    // 将ThreadCache保存在线程本地空间中.
    // 同时设置慢查找(大内存)的最小大小
    threadlocal_data_.heap = heap;
    SetMinSizeForSlowPath(kMaxSize + 1);
#endif
    heap->in_setspecific_ = false;
  }
  return heap;
}
// line:  396
#+END_SRC
    [[NewHeap]]

    #<<NewHeap>>
#+BEGIN_SRC cpp
// line:  398 file: /root/git/gperftools/src/thread_cache.cc
ThreadCache* ThreadCache::NewHeap(pthread_t tid) {
  // Create the heap and add it to the linked list
  // 创建heap结点并添加到双向链表中,非环形链表
  // threadcache_allocator 即为 Central Heap ?? 应该不是.
  ThreadCache *heap = threadcache_allocator.New();
  heap->Init(tid);
  heap->next_ = thread_heaps_;
  heap->prev_ = NULL;
  if (thread_heaps_ != NULL) {
    thread_heaps_->prev_ = heap;
  } else {
    ASSERT(next_memory_steal_ == NULL);
    // 这个变量是用于线程间内存偷取用.
    // 也就是线程A可以偷取线程B的空闲内存.
    // 此处是由于链表为空,所以将偷取对象设置为自己.
    next_memory_steal_ = heap;
  }
  thread_heaps_ = heap;
  thread_heap_count_++;
  return heap;
}
// line:  414
#+END_SRC
    [[thread\_allocator\_New]]

    #<<thread\_allocator\_New>>
#+BEGIN_SRC cpp
// line:   62 file: /root/git/gperftools/src/page_heap_allocator.h
  T* New() {
    // 一个内存管理模版.
    // Consult free list
    void* result;
    if (free_list_ != NULL) {
      result = free_list_;
      free_list_ = *(reinterpret_cast<void**>(result));
    } else {
      if (free_avail_ < sizeof(T)) {
        // Need more room. We assume that MetaDataAlloc returns
        // suitably aligned memory.
        free_area_ = reinterpret_cast<char*>(MetaDataAlloc(kAllocIncrement));
        if (free_area_ == NULL) {
          Log(kCrash, __FILE__, __LINE__,
              "FATAL ERROR: Out of memory trying to allocate internal "
              "tcmalloc data (bytes, object-size)",
              kAllocIncrement, sizeof(T));
        }
        free_avail_ = kAllocIncrement;
      }
      result = free_area_;
      free_area_ += sizeof(T);
      free_avail_ -= sizeof(T);
    }
    inuse_++;
    return reinterpret_cast<T*>(result);
  }
// line:   87
#+END_SRC
