* tcmalloc2.1 浅析

** 简介
   tcmalloc(thread cached malloc) 是由google为并发程序而开发的内存分配管理器.tcmalloc致力于
   减少多线程内存请求时对锁的竞争, 在对小内存的申请时, 可以在无需锁的
   情况下高效获取内存;而在获取大内存时,使用高校的spinlocks.正因为
   tcmalloc是在线程局部空间(TLS)预先存储部分空闲内存用于分配, 在程序刚
   启动时,其所占用的内存会比dlmalloc或其他的内存管理器更大,但其增长速
   幅度比其他管理器小,所以,在后期,实际占用内存空间会相接近.

** 原理简析

*** overview

    [[https://raw.githubusercontent.com/pengzhangdev/documents/master/tcmalloc/overview.gif]]


    tcmalloc为每一个线程分配一个线程本地缓存(Thread Cache)．所有小对象
    (<256K)都会优先从Thread Cache分配．而当Thread Cache没有足够空闲内
    存时，就会从Central Heap申请内存. 而当Thread Cache内存富裕时,会将
    内存返回给Central Heap. Central Heap 是以进程为单位存在,Thread
    Cache是以线程为单位存在.
    对于大内存(>256K), 直接从Page Heap 按页对齐(4K)申请.
    通常情况下, 一连串的页面(4k)可以多个小内存序列,每个序列元素等大小.
    TC, CC, PH 的关系是, TC 向CC申请内存并GC给CC. CC 向PH 申请内存并GC
    给PH.
    在TC中的数据单位时字节, 按大小为单位分类,每个类中时链表.
    在PH中的数据单位时Page(4K), 按PageNum分类,每个分类内部用链表管理,
    第PageNum类的链表结点为PageNum个Page.
    在CC中存在最多的数据结构,它连接着TC和PH. 其存放了来自CC的slot结构,
    和来自PH的PH的span结构.
    数据的移动. 所有的数据从TC<->CC<->PH 都是批量(batch)移动.从TC申请
    或释放的内存都会优先从CC的slots数组处理. slots存放的就是最近从TC释
    放的内存,用于快速的TC内存申请.如果slots条件不满足,就会操作CC中的
    spans对象.所有移动的数据的大小和TC中的最大大小都是在动态调整的.

*** 小对象内存分配
    [[https://raw.githubusercontent.com/pengzhangdev/documents/master/tcmalloc/threadheap.gif]]
    上图为小内存管理时的sizemap分类的示意图.小内存的管理都处于
    ThreadCache中.

** 代码review

** 总结
   + 对图表的几个说明:
     + 图表是在线程数为4的基础上做的测试. 并且是在连续分配一定次数的内
       存后再连续释放,数据只能从一定程度上反映了tcmalloc与dlmalloc的性
       能差异.
     + 本次测试是计算出4个线程的内存请求和释放的平均时间, 和标准偏差.由
       于图表维度不够,只使用了平均时间作为实际的性能比较.
     + 测试时的两个变量分别为, 单次申请内存大小,和申请次数,性能指标为
       执行所有内存申请释放的线程平均时间.
     + 该数据不包含内存分配器初始化的时间(即,第一次内存分配时间).实际
       上,内存分配器初始化,tcmalloc花费的时间是dlmalloc多.但只
       是针对第一次,所以,不记录到图标数据中.
     + 以下所有提到的内存申请数,如未说明,都是指单次内存申请的大小.

   + 分析:
     + tcmalloc 内存分配概要:
       + tcmalloc 中存在分级请求内存的机制. 分为3级,分别为
         TC(ThreadCache), CC(Central Cache) 和 PH(PageHeap)
       + TC 向CC 申请内存, CC 向PH申请内存. 而他们之间的内存是批量移动,一
         般为申请内存对齐后的N倍进行移动.
       + TC 存在线程局部空间中. 向TC 申请内存不需要加解锁,向CC和PH 申
         请内存需要加解锁.
     + dlmalloc 内存分配概要:
       + dlmalloc每次内存申请都会执行加解锁操作.
       + 256byte以下的内存,从小内存分配. 256byte以上的从大内存分配.在
         空闲内存不够并且申请内存大于256K的,直接由mmap分配.

     + 首先,从图表可以得出一个结论,在单次内存30K以内的内存分配和释放,
       效率上,tcmalloc比dlmalloc高,并且在1K以内,申请次数大于26次的情况
       下,甚至可以达到10倍性能.原因是,在tcmalloc中,所有小于256k的内存
       都会优先从TC(避免加解锁操作)分配, 在TC不够的情况下,向CC申请 2 -
       32 倍的内存数量,并存放到TC中,相当于, N(N>2)次内存请求才执行1次
       加解锁. 而dlmalloc每次内存请求都会加解锁.所以,tcmalloc在小内存
       分配上,性能高于dlmalloc.
     + 而在30K - 256K, 在某些区域内,tcmalloc的性能反而不如dlmalloc. 可
       能原因如下: tcmalloc在每次往CC中拷贝数据时, 有个大小上限为64K,
       也有一个最小下限为2倍请求内存对齐后的大小. 所以,在这个
       区间内,相当于每2次内存请求都会加解一次锁. 而CC也有
       存在内存不足的情况,也会出现加解锁,进一步向PH申请空间. 所以,就相
       当于每次内存申请都会加解锁.至于,在申请次数达到一定值之
       后,tcmalloc的性能又高于dlmalloc的原因是:CC与PH之间的内存移动的
       值是动态修正的,也就是说,在申请次数达到一定值之后,CC向PH申请的内
       存数变大,而请求次数减少,导致tcmalloc的性能再次提升.
     + > 256K 的情况下,tcmalloc的性能也略好于dlmalloc. 原因未知.分析如
       下. 在这种情况下,对于dlmalloc而言,如果没有足够
       空闲内存(本次测试中不可能有足够空闲内存), dlmalloc会直接调用
       mmap进行内存分配, 相当与一次加解锁,一次系统调用的时间.而
       tcmalloc依然向PH申请内存,当然PH也会直接从系统分配.

   + 结论: (以下结论,只有1从图表中得出)
     + 大量小内存请求的情况下,tcmalloc性能高于dlmalloc, 节省了加解锁的
       时间.
     + 如果只存在少量的内存请求,即使是小内存,从总的申请内存时间
       上,dlmalloc会优于tcmalloc,原因是,在第一次内存申请时,tcmalloc初
       始化的时间是dlmalloc的近10倍.
     + 从代码中分析,tcmalloc的内存利用率小于dlmalloc,虽然,tcmalloc使用
       了各种算法来提高内存利用率,但依然无法避免线程局部空间中的内存浪
       费.

   + 该测试的局限性:
     + 由于该测试是连续内存申请之后,连续释放,所以无法测试申请已释放内
       存的效率.但从代码上和tcmalloc/dlmalloc加解锁的机制上看,tcmalloc
       依然会优于dlmalloc.
     + 无法测试对于生命周期超长的进程,内存的碎片率.


** 草稿

+ 主要函数
#+BEGIN_SRC cpp
extern "C" PERFTOOLS_DLL_DECL void* tc_malloc(size_t size) __THROW
extern "C" PERFTOOLS_DLL_DECL void tc_free(void* ptr) __THROW
extern "C" PERFTOOLS_DLL_DECL void* tc_calloc(size_t n,
                                              size_t elem_size) __THROW
extern "C" PERFTOOLS_DLL_DECL void tc_cfree(void* ptr) __THROW
extern "C" PERFTOOLS_DLL_DECL void* tc_realloc(void* old_ptr,
                                               size_t new_size) __THROW
extern "C" PERFTOOLS_DLL_DECL void* tc_new(size_t size)
extern "C" PERFTOOLS_DLL_DECL void tc_delete(void* p) __THROW
#+END_SRC

   真正分配内存的函数是do_malloc函数.

*** tc_malloc

#+BEGIN_SRC cpp
// line: 1577 file: /root/git/gperftools/src/tcmalloc.cc
extern "C" PERFTOOLS_DLL_DECL void* tc_malloc(size_t size) __THROW {
  void* result = do_malloc_or_cpp_alloc(size);
  MallocHook::InvokeNewHook(result, size);
  return result;
}
// line: 1581
#+END_SRC

#+BEGIN_SRC cpp
// line: 1038 file: /root/git/gperftools/src/tcmalloc.cc
inline void* do_malloc_or_cpp_alloc(size_t size) {
  // tc_new_mode 是指是否使用cpp的new来替换malloc实现.
  // 默认情况下为使用malloc, 所以代码进入do_malloc(size);
  return tc_new_mode ? cpp_alloc(size, true) : do_malloc(size);
}
// line: 1041
#+END_SRC

#+BEGIN_SRC cpp
// line: 1118 file: /root/git/gperftools/src/tcmalloc.cc
inline void* do_malloc(size_t size) {
  void* ret = do_malloc_no_errno(size);
  // UNLIKELY 是gcc的优化扩展,表示其测试成立条件极低.
  //
  if (UNLIKELY(ret == NULL)) errno = ENOMEM;
  return ret;
}
// line: 1123
#+END_SRC
    [[UNLIKELY][UNLIKELY]]

#+BEGIN_SRC cpp
// line: 1107 file: /root/git/gperftools/src/tcmalloc.cc
inline void* do_malloc_no_errno(size_t size) {
  if (ThreadCache::have_tls &&
      LIKELY(size < ThreadCache::MinSizeForSlowPath())) {
    // 这里的逻辑实际上与 size <= kMaxSize类似.
    // 区别是,下面的逻辑会进行ThreadCache的初始化.
    // 而这里是直接获取ThreadCache中的Heap.
    return do_malloc_small(ThreadCache::GetCacheWhichMustBePresent(), size);
   // kMaxSize = 256 * 1024
  } else if (size <= kMaxSize) {
    // ThreadCache::GetCache 中会进行TC的初始化.
    return do_malloc_small(ThreadCache::GetCache(), size);
  } else {
    return do_malloc_pages(ThreadCache::GetCache(), size);
  }
}
// line: 1117
#+END_SRC
    [[MinSizeForSlowPath]]
    [[tcmalloc_tc_init]]

    #<<MinSizeForSlowPath>>
#+BEGIN_SRC cpp
// line:  436 file: /root/git/gperftools/src/thread_cache.h
inline size_t ThreadCache::MinSizeForSlowPath() {
#ifdef HAVE_TLS
  // 这里min_size_for_slow_path = kMaxSize + 1;
  // 具体设置这个值,在后面初始化时会提到.
  return threadlocal_data_.min_size_for_slow_path;
#else
  return 0;
#endif
}
// line:  443
#+END_SRC

    #<<UNLIKELY>>
#+BEGIN_SRC cpp
// line:   49 file: /root/git/gperftools/src/common.h
#define UNLIKELY(x) __builtin_expect(!!(x), 0)
// line:   49
#+END_SRC

    #<<tcmalloc_tc_init>>
#+BEGIN_SRC cpp
// line:  417 file: /root/git/gperftools/src/thread_cache.h
inline ThreadCache* ThreadCache::GetCache() {
  ThreadCache* ptr = NULL;
  if (!tsd_inited_) {
    // init Module, global data
    InitModule();
  } else {
    ptr = GetThreadHeap();
  }
  //  init ThreadCache
  if (ptr == NULL) ptr = CreateCacheIfNecessary();
  return ptr;
}
// line:  427
#+END_SRC
    [[InitModule]]
    [[CreateCacheIfNecessary]]

    #<<InitModule>>
#+BEGIN_SRC cpp
// line:  314 file: /root/git/gperftools/src/thread_cache.cc
void ThreadCache::InitModule() {
  SpinLockHolder h(Static::pageheap_lock());
  if (!phinited) {
    // 从环境变量 TCMALLOC_MAX_TOTAL_THREAD_CACHE_BYTES 获取ThreadCache的最大值
    const char *tcb = TCMallocGetenvSafe("TCMALLOC_MAX_TOTAL_THREAD_CACHE_BYTES");
    if (tcb) {
      set_overall_thread_cache_size(strtoll(tcb, NULL, 10));
    }
    // 进程空间变量和alloctor初始化.
    Static::InitStaticVars();
    threadcache_allocator.Init();
    phinited = 1;
  }
}
// line:  325
#+END_SRC
    [[InitStaticVars]]
    [[allocator_init]]

    #<<InitStaticVars>>
#+BEGIN_SRC cpp
// line:   81 file: /root/git/gperftools/src/static_vars.cc
void Static::InitStaticVars() {
  // sizemap 初始化
  // 类似dlmalloc的分箱机制.
  // 按固定大小进行分类,在每个分类中存放对应大小的双向链表.
  sizemap_.Init();
  // 初始化span分配器
  span_allocator_.Init();
  span_allocator_.New(); // Reduce cache conflicts
  span_allocator_.New(); // Reduce cache conflicts
  stacktrace_allocator_.Init();
  bucket_allocator_.Init();
  // Do a bit of sanitizing: make sure central_cache is aligned properly
  CHECK_CONDITION((sizeof(central_cache_[0]) % 64) == 0);
  // 初始化central_cache_ 分类列表.
  for (int i = 0; i < kNumClasses; ++i) {
    central_cache_[i].Init(i);
  }

  // It's important to have PageHeap allocated, not in static storage,
  // so that HeapLeakChecker does not consider all the byte patterns stored
  // in is caches as pointers that are sources of heap object liveness,
  // which leads to it missing some memory leaks.
  // 初始化 PageHeap
  pageheap_ = new (MetaDataAlloc(sizeof(PageHeap))) PageHeap;
  // double linked list init
  DLL_Init(&sampled_objects_);
  Sampler::InitStatics();
}
// line:  102
#+END_SRC
    [[sizemap_init]]

    #<<sizemap_init>>
#+BEGIN_SRC cpp
// line:  122 file: /root/git/gperftools/src/common.cc
void SizeMap::Init() {
  // 初始化TC中对应TransferNumObjects.
  // TransferNumObjects 是
  InitTCMallocTransferNumObjects();

  // Do some sanity checking on add_amount[]/shift_amount[]/class_array[]
  // class 分类边界检查.
  // size 0 应该对应分类0
  // size Max 应该对应分类Max
  if (ClassIndex(0) != 0) {
    Log(kCrash, __FILE__, __LINE__,
        "Invalid class index for size 0", ClassIndex(0));
  }
  if (ClassIndex(kMaxSize) >= sizeof(class_array_)) {
    Log(kCrash, __FILE__, __LINE__,
        "Invalid class index for kMaxSize", ClassIndex(kMaxSize));
  }

  // Compute the size classes we want to use
  // 计算size classe 分类大小, 和对应的每个分类对应的
  // 计算结果如下:
  // class 1 :
  int sc = 1;   // Next size class to assign
  int alignment = kAlignment;
  CHECK_CONDITION(kAlignment <= kMinAlign);
  for (size_t size = kAlignment; size <= kMaxSize; size += alignment) {
    alignment = AlignmentForSize(size);
    CHECK_CONDITION((size % alignment) == 0);

    int blocks_to_move = NumMoveSize(size) / 4;
    size_t psize = 0;
    do {
      psize += kPageSize;
      // Allocate enough pages so leftover is less than 1/8 of total.
      // This bounds wasted space to at most 12.5%.
      while ((psize % size) > (psize >> 3)) {
        psize += kPageSize;
      }
      // Continue to add pages until there are at least as many objects in
      // the span as are needed when moving objects from the central
      // freelists and spans to the thread caches.
    } while ((psize / size) < (blocks_to_move));
    const size_t my_pages = psize >> kPageShift;

    if (sc > 1 && my_pages == class_to_pages_[sc-1]) {
      // See if we can merge this into the previous class without
      // increasing the fragmentation of the previous class.
      const size_t my_objects = (my_pages << kPageShift) / size;
      const size_t prev_objects = (class_to_pages_[sc-1] << kPageShift)
                                  / class_to_size_[sc-1];
      if (my_objects == prev_objects) {
        // Adjust last class to include this size
        class_to_size_[sc-1] = size;
        continue;
      }
    }

    // Add new class
    class_to_pages_[sc] = my_pages;
    class_to_size_[sc] = size;
    sc++;
  }
  if (sc != kNumClasses) {
    Log(kCrash, __FILE__, __LINE__,
        "wrong number of size classes: (found vs. expected )", sc, kNumClasses);
  }

  // Initialize the mapping arrays
  int next_size = 0;
  for (int c = 1; c < kNumClasses; c++) {
    const int max_size_in_class = class_to_size_[c];
    for (int s = next_size; s <= max_size_in_class; s += kAlignment) {
      class_array_[ClassIndex(s)] = c;
    }
    next_size = max_size_in_class + kAlignment;
  }

  // Double-check sizes just to be safe
  for (size_t size = 0; size <= kMaxSize;) {
    const int sc = SizeClass(size);
    if (sc <= 0 || sc >= kNumClasses) {
      Log(kCrash, __FILE__, __LINE__,
          "Bad size class (class, size)", sc, size);
    }
    if (sc > 1 && size <= class_to_size_[sc-1]) {
      Log(kCrash, __FILE__, __LINE__,
          "Allocating unnecessarily large class (class, size)", sc, size);
    }
    const size_t s = class_to_size_[sc];
    if (size > s || s == 0) {
      Log(kCrash, __FILE__, __LINE__,
          "Bad (class, size, requested)", sc, s, size);
    }
    if (size <= kMaxSmallSize) {
      size += 8;
    } else {
      size += 128;
    }
  }

  // Initialize the num_objects_to_move array.
  for (size_t cl = 1; cl  < kNumClasses; ++cl) {
    num_objects_to_move_[cl] = NumMoveSize(ByteSizeForClass(cl));
  }
}
// line:  218
#+END_SRC
    [[AlignmentForSize]]

    #<<AlignmentForSize>>
#+BEGIN_SRC cpp
// kPageShift = 13
// kNumClasses = 88
// kMinAlign = 16
// kAlignment  = 8
// kMaxSize    = 256 * 1024
// kPageSize   = 1 << kPageShift

// 计算结果如下:
// size         alignment
// >kMaxSize    kPageSize;
// >=128
// >= 16        16
// >= 8         8
int AlignmentForSize(size_t size) {
  int alignment = kAlignment;
  if (size > kMaxSize) {
    // Cap alignment at kPageSize for large sizes.
    alignment = kPageSize;
  } else if (size >= 128) {
    // Space wasted due to alignment is at most 1/8, i.e., 12.5%.
    alignment = (1 << LgFloor(size)) / 8;
  } else if (size >= kMinAlign) {
    // We need an alignment of at least 16 bytes to satisfy
    // requirements for some SSE types.
    alignment = kMinAlign;
  }
  // Maximum alignment allowed is page size alignment.
  if (alignment > kPageSize) {
    alignment = kPageSize;
  }
  CHECK_CONDITION(size < kMinAlign || alignment >= kMinAlign);
  CHECK_CONDITION((alignment & (alignment - 1)) == 0);
  return alignment;
}
#+END_SRC

    #<<allocator_init>>

    #<<CreateCacheIfNecessary>>
#+BEGIN_SRC cpp
// line:  345 file: /root/git/gperftools/src/thread_cache.cc
ThreadCache* ThreadCache::CreateCacheIfNecessary() {
  // Initialize per-thread data if necessary
  ThreadCache* heap = NULL;
  {
    SpinLockHolder h(Static::pageheap_lock());
    // 在某些老旧的glibc或者类unix系统中,如果在tcmalloc中过早调用pthread_self(),
    // 则会有可能引起崩溃.
#ifdef PTHREADS_CRASHES_IF_RUN_TOO_EARLY
    pthread_t me;
    if (!tsd_inited_) {
      memset(&me, 0, sizeof(me));
    } else {
      me = pthread_self();
    }
#else
    const pthread_t me = pthread_self();
#endif

    // 可能在之前, ThreadCache链表.
    // 初始化了. 我们先尝试搜索匹配该tid的ThreadCache结构.
    for (ThreadCache* h = thread_heaps_; h != NULL; h = h->next_) {
      if (h->tid_ == me) {
        heap = h;
        break;
      }
    }

    if (heap == NULL) heap = NewHeap(me);
  }

  // We call pthread_setspecific() outside the lock because it may
  // call malloc() recursively.  We check for the recursive call using
  // the "in_setspecific_" flag so that we can avoid calling
  // pthread_setspecific() if we are already inside pthread_setspecific().
  if (!heap->in_setspecific_ && tsd_inited_) {
    heap->in_setspecific_ = true;
    perftools_pthread_setspecific(heap_key_, heap);
#ifdef HAVE_TLS
    // 将ThreadCache保存在线程本地空间中.
    // 同时设置慢查找(大内存)的最小大小
    threadlocal_data_.heap = heap;
    SetMinSizeForSlowPath(kMaxSize + 1);
#endif
    heap->in_setspecific_ = false;
  }
  return heap;
}
// line:  396
#+END_SRC
    [[NewHeap]]

    #<<NewHeap>>
#+BEGIN_SRC cpp
// line:  398 file: /root/git/gperftools/src/thread_cache.cc
ThreadCache* ThreadCache::NewHeap(pthread_t tid) {
  // Create the heap and add it to the linked list
  // 创建heap结点并添加到双向链表中,非环形链表
  // threadcache_allocator 即为 Central Heap ?? 应该不是.
  ThreadCache *heap = threadcache_allocator.New();
  heap->Init(tid);
  heap->next_ = thread_heaps_;
  heap->prev_ = NULL;
  if (thread_heaps_ != NULL) {
    thread_heaps_->prev_ = heap;
  } else {
    ASSERT(next_memory_steal_ == NULL);
    // 这个变量是用于线程间内存偷取用.
    // 也就是线程A可以偷取线程B的空闲内存.
    // 此处是由于链表为空,所以将偷取对象设置为自己.
    next_memory_steal_ = heap;
  }
  thread_heaps_ = heap;
  thread_heap_count_++;
  return heap;
}
// line:  414
#+END_SRC
    [[thread_allocator_New]]

    #<<thread_allocator_New>>
#+BEGIN_SRC cpp
// line:   62 file: /root/git/gperftools/src/page_heap_allocator.h
  T* New() {
    // 一个内存管理模版.
    // Consult free list
    void* result;
    if (free_list_ != NULL) {
      result = free_list_;
      free_list_ = *(reinterpret_cast<void**>(result));
    } else {
      if (free_avail_ < sizeof(T)) {
        // Need more room. We assume that MetaDataAlloc returns
        // suitably aligned memory.
        free_area_ = reinterpret_cast<char*>(MetaDataAlloc(kAllocIncrement));
        if (free_area_ == NULL) {
          Log(kCrash, __FILE__, __LINE__,
              "FATAL ERROR: Out of memory trying to allocate internal "
              "tcmalloc data (bytes, object-size)",
              kAllocIncrement, sizeof(T));
        }
        free_avail_ = kAllocIncrement;
      }
      result = free_area_;
      free_area_ += sizeof(T);
      free_avail_ -= sizeof(T);
    }
    inuse_++;
    return reinterpret_cast<T*>(result);
  }
// line:   87
#+END_SRC
